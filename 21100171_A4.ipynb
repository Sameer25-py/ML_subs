{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np \n",
    "import re\n",
    "import time\n",
    "from math import log\n",
    "from os import system\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting all files path\n",
    "def get_files(path):\n",
    "    files =[]\n",
    "    for file in glob.glob(path+'pos/*.*'):\n",
    "        files.append(file)\n",
    "    for file in glob.glob(path+'/neg/*.*'):\n",
    "        files.append(file)\n",
    "    return files\n",
    "\n",
    "train_files = get_files('./dataset/train/')\n",
    "test_files = get_files('./dataset/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end-time 144.26308822631836\n",
      "end-time 154.29385614395142\n"
     ]
    }
   ],
   "source": [
    "#reading and storing all files data,labels and ratings\n",
    "def get_data(files):\n",
    "    start_time = time.time()\n",
    "    data = []\n",
    "    labels=[]\n",
    "    for file in files:\n",
    "        with open(file,encoding='utf-8') as f:\n",
    "            raw = f.read()\n",
    "            data.append(raw)\n",
    "            if 'pos' in file:\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                labels.append(0)\n",
    "            f.close()\n",
    "    print('end-time',time.time()-start_time)\n",
    "    return data,labels\n",
    "train_data,train_labels = get_data(train_files)\n",
    "test_data,test_labels = get_data(test_files) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading stopwords\n",
    "def get_wordlists(file):\n",
    "    data = []\n",
    "    with open(file,'r') as f:\n",
    "        data = [i.strip(\"\\n\").lower() for i in f.readlines()]\n",
    "    f.close()\n",
    "    return data\n",
    "stopwords = get_wordlists('./dataset/stop_words.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end-time 3.1119191646575928\n",
      "end-time 2.91359281539917\n"
     ]
    }
   ],
   "source": [
    "#preprocessing removing every character excpet alphabets\n",
    "def preprocessing(data,stopwords):\n",
    "    start_time = time.time()\n",
    "    sentences = []\n",
    "    tokens = []\n",
    "    filter_ = lambda x: len(x.strip(\" \")) > 5  \n",
    "    for i,review in enumerate(data):\n",
    "        sentences.append(re.sub('[^a-z]+',\" \",review.lower()))\n",
    "    for i in sentences:\n",
    "        temp = []\n",
    "        for word in i.split(\" \"):\n",
    "            if len(word) > 5: #eliminating word with len <5\n",
    "                temp.append(word)\n",
    "        tokens.append(temp)\n",
    "    print('end-time',time.time()-start_time)\n",
    "    return tokens\n",
    "train_tokens = preprocessing(train_data,stopwords)\n",
    "test_tokens = preprocessing(test_data,stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting vocab\n",
    "def extract_vocab(tokens):\n",
    "    return list(set([i for x in tokens for i in x]))\n",
    "vocab = extract_vocab(train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end-time 1824.8439095020294\n"
     ]
    }
   ],
   "source": [
    "#Part1\n",
    "#counts of vocab in pos and negative corpus\n",
    "def class_counts(tokens,labels,vocab):\n",
    "    start_time = time.time()\n",
    "    pos_tokens = [y for x in [tokens[i] for i in range(len(tokens)) if labels[i] == 1] for y in x]\n",
    "    neg_tokens = [y for x in [tokens[i] for i in range(len(tokens)) if labels[i] == 0] for y in x]\n",
    "    pos_counts = list(map(lambda x: pos_tokens.count(x),vocab))\n",
    "    neg_counts = list(map(lambda x: neg_tokens.count(x),vocab))\n",
    "    print('end-time',time.time()-start_time)\n",
    "    return pos_counts,neg_counts\n",
    "pos,neg = class_counts(train_tokens,train_labels,vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #flatten neg and pos corpuses\n",
    "    train_positive_corpus = [y for x in [train_tokens[i] for i in range(len(train_tokens)) if train_labels[i] == 1] for y in x]\n",
    "    train_negative_corpus = [y for x in [train_tokens[i] for i in range(len(train_tokens)) if train_labels[i] == 0] for y in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes variables\n",
    "prior_class = log(0.5)\n",
    "docs_per_class = 12500\n",
    "total_docs = 25000\n",
    "vocab_len = len(vocab)\n",
    "pos_corp_len = len(train_positive_corpus)\n",
    "neg_corp_len = len(train_negative_corpus)\n",
    "\n",
    "#prediction function to sum and compute likelihoods\n",
    "def predict(pos_counts,neg_counts,vocab,subject):\n",
    "    negative_probs =[]\n",
    "    positive_probs = []\n",
    "    for i in range(len(subject)):\n",
    "        pos_count = 0\n",
    "        neg_count = 0\n",
    "        if subject[i] in vocab:\n",
    "            index = vocab.index(subject[i])\n",
    "            pos_count = pos_counts[index]\n",
    "            neg_count = neg_counts[index]\n",
    "        negative_probs.append( log ((neg_count+1)/(neg_corp_len + vocab_len)) )\n",
    "        positive_probs.append( log ((pos_count+1)/(pos_corp_len + vocab_len)) )\n",
    "    return np.argmax([np.sum(negative_probs) + prior_class , np.sum(positive_probs) + prior_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end-time 5421.596265792847\n"
     ]
    }
   ],
   "source": [
    "#predicitng test corpus\n",
    "correct = 0\n",
    "start_time = time.time()\n",
    "predictions = list(map(lambda x: predict(pos,neg,vocab,x),test_tokens))\n",
    "print('end-time',time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURRACY ON TEST DATA 0.81012\n"
     ]
    }
   ],
   "source": [
    "#calculating accuracy\n",
    "correct = 0\n",
    "for i,x in enumerate(predictions):\n",
    "    if x == test_labels[i]:\n",
    "        correct+=1\n",
    "print(\"ACCURRACY ON TEST DATA\",correct/len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part2\n",
    "#convert tokens to strings\n",
    "def tokens_to_str(tokens):\n",
    "    return [\" \".join(i) for i in tokens]\n",
    "train = tokens_to_str(train_tokens)\n",
    "test = tokens_to_str(test_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count vectorizer model\n",
    "model = CountVectorizer().fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tranforming train and test corpus using model fitted on train corpus\n",
    "train_vec = model.transform(train)\n",
    "test_vec = model.transform(test)\n",
    "#initializing naive bayes\n",
    "clf = MultinomialNB().fit(train_vec,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY SCORE: 0.81012\n"
     ]
    }
   ],
   "source": [
    "#prediciting test corpus\n",
    "predictions2 = clf.predict(test_vec)\n",
    "print('ACCURACY SCORE:',accuracy_score(predictions2,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10854,  3101],\n",
       "       [ 1646,  9399]], dtype=int64)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(predictions2,test_labels,labels=[0,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
